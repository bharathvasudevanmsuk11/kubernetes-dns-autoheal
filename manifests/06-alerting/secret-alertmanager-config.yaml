apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-prometheus-kube-prometheus-alertmanager
  namespace: monitoring
type: Opaque
stringData:
  alertmanager.yaml: |
    global:
      resolve_timeout: 5m
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
      
    route:
      receiver: 'default'
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 5m
      repeat_interval: 12h
      routes:
      - match:
          severity: critical
        receiver: 'pagerduty-critical'
        continue: true
      - match:
          severity: critical
          escalate: manager
        receiver: 'manager-email'
        continue: true
      - match:
          team: sre
        receiver: 'sre-slack'
        continue: true
      - match:
          severity: warning
        receiver: 'sre-email'
        
    receivers:
    - name: 'default'
      webhook_configs:
      - url: 'http://remediation-webhook.monitoring.svc.cluster.local:8080/remediate'
        send_resolved: true
        
    - name: 'sre-slack'
      slack_configs:
      - channel: '#sre-alerts'
        username: 'Alertmanager'
        icon_emoji: ':warning:'
        title: '{{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Remediation:* {{ .Annotations.remediation }}
          *Runbook:* {{ .Annotations.runbook_url }}
          {{ end }}
        send_resolved: true
        
    - name: 'sre-email'
      email_configs:
      - to: 'sre-team@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'alerts@company.com'
        auth_password: 'YOUR_APP_PASSWORD'
        headers:
          Subject: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        html: |
          <h2>{{ .GroupLabels.alertname }}</h2>
          {{ range .Alerts }}
          <h3>{{ .Annotations.summary }}</h3>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          <p><strong>Severity:</strong> {{ .Labels.severity }}</p>
          <p><strong>Remediation:</strong> {{ .Annotations.remediation }}</p>
          {{ end }}
        send_resolved: true
        
    - name: 'manager-email'
      email_configs:
      - to: 'engineering-manager@company.com'
        from: 'alertmanager@company.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'alerts@company.com'
        auth_password: 'YOUR_APP_PASSWORD'
        headers:
          Subject: '[CRITICAL ESCALATION] {{ .GroupLabels.alertname }}'
        html: |
          <h2 style="color:red;">CRITICAL ESCALATION REQUIRED</h2>
          <p>A critical DNS throttling issue requires immediate attention.</p>
          {{ range .Alerts }}
          <h3>{{ .Annotations.summary }}</h3>
          <p><strong>Description:</strong> {{ .Annotations.description }}</p>
          {{ end }}
          
    - name: 'pagerduty-critical'
      pagerduty_configs:
      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'
        description: '{{ .GroupLabels.alertname }} - {{ .Annotations.summary }}'
        details:
          severity: '{{ .Labels.severity }}'
          description: '{{ .Annotations.description }}'
